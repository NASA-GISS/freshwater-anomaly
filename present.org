#+TITLE: Freshwater Anomalies
#+AUTHOR: K. D. Mankoff

#+EMAIL:  ken.mankoff@nasa.gov
#+DATE: \tiny{ {{{time(%Y-%m-%d)}}} version:\input{|"git describe --always --dirty='*'"} } 

# version:\input{|"git describe --always --dirty='*'"}}}}}
# #+DATE: \tiny{2020-02-05} @@latex:\\@@ { \tiny version:\input{|"git describe --always --dirty='*'"}}

#+MACRO: NEWLINE @@latex:\\@@ @@html:<br>@@
#+MACRO: SKIPLINE @@latex:\\\vspace{\baselineskip}@@

#+DESCRIPTION:
#+KEYWORDS:
#+LANGUAGE:  en
#+OPTIONS:   H:2 num:nil ^:{} toc:nil

#+EXCLUDE_TAGS: noexport
#+ARCHIVE: ::* Archive

#+PROPERTY: header-args :eval no-export :noweb yes
# #+PROPERTY: header-args:jupyter-python :session MC-LOB :eval no-export :noweb yes :exports results :results raw drawer
# #+PROPERTY: header-args:jupyter-python+ :var datadir="/home/kdm/projects/freshwater/freshwater/runoff/"

* COMMENT Table of contents                       :toc_2:noexport:
- [[#introduction][Introduction]]
  - [[#summary][Summary]]
  - [[#numbers-and-units][Numbers and units]]
  - [[#overview-numbers][Overview numbers]]
  - [[#global-ice-mass-change][Global ice mass change]]
  - [[#slater-2021-fig-4-recreation][Slater 2021 Fig. 4 recreation]]
  - [[#issues][Issues]]
- [[#greenland][Greenland]]
  - [[#mankoff-2021][Mankoff 2021]]
  - [[#most-of-the-anomaly-is-smb][Most of the anomaly is SMB]]
  - [[#fetch-historical-observations][Fetch historical observations]]
  - [[#compare-mankoff-2021--slater-2021][Compare Mankoff 2021 & Slater 2021]]
  - [[#greenlandic-peripheral-glaciers][Greenlandic Peripheral glaciers]]
  - [[#greenlandic-icebergs-vs-runoff--submarine-melt][Greenlandic icebergs vs. (runoff & submarine melt)]]
  - [[#greenland-mass-loss-by-roi-gt-yr-1][Greenland mass loss by ROI [Gt yr^{-1}]]]
  - [[#greenland-mass-loss-by-roi-][Greenland mass loss by ROI]]
  - [[#greenland-mass-balance-annual][Greenland mass balance (annual)]]
  - [[#greenland-mass-balance-monthly][Greenland mass balance (monthly)]]
  - [[#comments-on-previous-slide][Comments on previous slide]]
  - [[#stream-discharge-baseline-gtmonth-1960--1989][Stream discharge: baseline [Gt/month] (1960--1989)]]
  - [[#stream-discharge-anomaly-gtmonth-1990--2019-base][Stream discharge: anomaly [Gt/month] ((1990--2019)-base)]]
  - [[#stream-discharge-anomaly--anom---basebase][Stream discharge: anomaly[(anom - base)/base]]]
  - [[#summary-1][Summary]]
- [[#antarctica][Antarctica]]
  - [[#imbie-2018][IMBIE 2018]]
  - [[#imbie-2018-vs-slater-2021][IMBIE 2018 vs Slater 2021]]
  - [[#antarctic-icebergs][Antarctic icebergs]]
  - [[#iceberg-distribution][Iceberg distribution]]
  - [[#fw-forcing-distribution][FW forcing distribution]]
- [[#freshwater-distribution-mask][Freshwater distribution mask]]
  - [[#introduction-1][Introduction]]
  - [[#existing-mask][Existing mask]]
  - [[#contents-of-glmelt_144x90_gasocnnc][Contents of GLMELT_144X90_gas.OCN.nc]]
  - [[#visualization-of-glmelt_144x90_gasocnnc][Visualization of GLMELT_144X90_gas.OCN.nc]]
  - [[#mask-editing][Mask editing]]
  - [[#new-mask-creation][New mask creation]]
  - [[#greenland-mask][Greenland mask]]
  - [[#antarctic-mask-][Antarctic mask ???]]
  - [[#new-mask-contents][New mask contents]]
  - [[#new-mask-visualization][New mask visualization]]
- [[#summary-2][Summary]]
  - [[#questions--to-do][Questions & To Do]]
- [[#appendix][Appendix]]
  - [[#references][References]]
  - [[#about-this-document][About This Document]]
- [[#latex-header][LaTeX Header]]
  - [[#beamer][Beamer]]
  - [[#references-1][References]]
  - [[#hyperref][Hyperref]]
  - [[#tweak-references][Tweak References]]
  - [[#background-block][Background Block]]
  - [[#code-export][Code export]]
- [[#local-variables][Local Variables]]

* Introduction
** Summary

This workbook computes freshwater anomaly from Greenland and Antarctica for the NASA GISS ModelE.

+ Anomaly is defined as mass loss since 1990
+ Spatially, ModelE distributes a single value according to a 'distribution field' - a floating point mask that sums to 1.

** Numbers and units

+ 1 Gt = 1 km^{3} (freshwater)
+ 360 Gt \(\approx\) 1 mm SLR
+ 1 Sv = 31556 km^{3} yr^{-1} (\(\sim\) \pi 10^{4} km^{3} yr^{-1})

** Overview numbers
:PROPERTIES:
:BEAMER_opt: shrink=9
:END:

#+BEGIN_SRC jupyter-python
import xarray as xr
ds = xr.open_dataset('/home/kdm/data/Mankoff_2021/203/MB_region.nc')\
    .sum(dim='region')\
    .resample({'time':'YS'})\
    .sum()['MB']

dd = ds.sel({'time':slice('1990-01-01','1999-12-31')}).mean(dim='time')
print('1990-1999: ', dd.data, dd.data/-362)

dd = ds.sel({'time':slice('1990-01-01','2019-12-31')}).mean(dim='time')
print('1990-2019: ', dd.data, dd.data/-362)

dd = ds.sel({'time':slice('2000-01-01','2019-12-31')}).mean(dim='time')
print('2000-2019: ', dd.data, dd.data/-362)

dd = ds.sel({'time':slice('2010-01-01','2019-12-31')}).mean(dim='time')
print('2010-2019: ', dd.data, dd.data/-362)

dd = ds.sel({'time':slice('2010-01-01','2019-12-31')}).resample({'time':'YS'}).mean()
dd = dd.where((dd.time.dt.year != 2019) & (dd.time.dt.year != 2012)).mean()
print('2010-2019 (excl 2012 & 2019): ', dd.data, dd.data/-362)
#+END_SRC

#+RESULTS:
: 1990-1999:  -67.26179 0.185806042581632
: 1990-2019:  -159.87126 0.44163331932784444
: 2000-2019:  -206.176 0.5695469471631129
: 2010-2019:  -246.02238 0.6796198470816428
: 2010-2019 (excl 2012 & 2019):  -203.1928 0.5613060629828859


+ Greenland *net* ice mass loss citep:mankoff_2021
  + \(\sim\)160 Gt yr^{-1} (0.44 mm yr^{-1}) since 1990
  + \(\sim\)200 Gt yr^{-1} (0.55 mm yr^{-1}) since 2000
  + \(\sim\)245 Gt yr^{-1} (0.68 mm yr^{-1}) since 2010

{{{SKIPLINE}}}

+ \(\sim\)500 Gt yr^{-1} is dynamic (outlet glacier discharge; citet:mankoff_2020_solid)
  + Distributed \(\sim\)50 % \pm40 % between submarine melt & icebergs citep:enderlin_2013
  + Fairly steady intra- and inter- annual
+ \(\sim\)300--500 Gt yr^{-1} is surface melt and runoff citep:mankoff_2017_VHD,mankoff_2020_liquid
  + Some surface rivers, most submarine
  + Highly seasonal (most in summer)
  + Highly variable interannual

{{{SKIPLINE}}}

+ From the above, ice sheet mass gain (snowfall) should be \(\sim\)600--800 Gt yr^{-1} 
+ Another \(\sim\)120 Gt yr^{-1} land runoff (rain/snow on non-ice-sheet land) citep:mankoff_2020_liquid

** Global ice mass change

citet:slater_2021 provides global ice mass change. This includes *ice shelf mass loss*, something not detected by GRACE and excluded from most mass change products. We use citet:slater_2021 in Antarctica.

+ Paper: https://doi.org/10.5194/tc-15-233-2021
+ Data: Shared via email (pers. comm.)
  + To be updated with DOI

{{{SKIPLINE}}}

In Greenland, we use citet:mankoff_2021 because it begins earlier, is continually updating, and ice shelf melting and thinning is negligible in Greenland relative to the other freshwater terms.

** Slater 2021 Fig. 4 recreation
*** Original                                               :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:

**** Original

[[./fig/slater_2021_fig4_orig.png]]


*** Recreation                                             :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
**** Recreation

#+BEGIN_SRC jupyter-python :results file :exports results :file ./fig/slater_2021_fig4.png
import pandas as pd

kw = {'parse_dates':True, 'index_col':0}
SH_ice = pd.read_csv('./input/SH_seaice_cumul_1994_2017_annual.csv', names=['Antarctic Sea Ice'], **kw)
NH_ice = pd.read_csv('./input/NH_seaice_cumul_1994_2017_annual.csv', names=['Arctic Sea Ice'], **kw)
shelf_calving = pd.read_csv('./input/iceshelves_calving_cumul_1994_2017_annual.csv', names=['Ice Shelf Calving'], **kw)
shelf_thinning = pd.read_csv('./input/iceshelves_thinning_cumul_1994_2017_annual.csv', names=['Ice Shelf Thinning'], **kw)
AQ = pd.read_csv('./input/AIS_cumul_1994_2017_annual.csv', names=['Antarctica'], **kw)
GL = pd.read_csv('./input/GrIS_cumul_1994_2017_annual.csv', names=['Greenland'], **kw)
glacier = pd.read_csv('./input/Glacier_cumul_1994_2017_annual.csv', names=['Glaciers'], **kw)

kw = {'left_index':True, 'right_index':True, 'how':'outer'}
df = SH_ice.merge(NH_ice, **kw)\
           .merge(shelf_calving, **kw)\
           .merge(shelf_thinning, **kw)\
           .merge(AQ, **kw)\
           .merge(GL, **kw)\
           .merge(glacier, **kw)
df.index.name = 'Date'

# df.plot.area() # NO
# Split positive and negative and plot separately but visually combined
# https://stackoverflow.com/questions/52872938/
import matplotlib.pyplot as plt
fig, ax = plt.subplots()
cm = 'GnBu'
df_neg, df_pos = df.clip(upper=0), df.clip(lower=0)
df_pos.plot.area(ax=ax, stacked=True, linewidth=0., cmap=cm)
ax.set_prop_cycle(None)
ax.set_ylim([-30000, 5000])
df_neg.plot.area(ax=ax, stacked=True, linewidth=0., legend=False, cmap=cm)
ax.set_ylim([-30000, 5000])
plt.hlines(0, 0, 1E3, color='k', linewidth=1, alpha=0.33, linestyles='dashed')
ax.set_ylabel('Mass change [Gt]')

plt.savefig('./fig/slater_2021_fig4.png', dpi=150)
#+END_SRC

#+RESULTS:
[[file:./fig/slater_2021_fig4.png]]



** Issues

+ Although citet:slater_2021 provide global ice mass change, the data is only from 1994 through 2017
+ We will use other products with longer records where possible, but use citet:slater_2021 for QC
+ We will extrapolate citet:slater_2021 forward and backward if no other product exists
  + i.e., Antarctic ice shelves

* Greenland
** Mankoff 2021

citet:mankoff_2021 provide *main ice sheet* mass loss from 1840 through next week.

{{{SKIPLINE}}}

+ Paper: https://doi.org/10.5194/essd-13-5001-2021
+ Data: https://doi.org/10.22008/FK2/OHI23Z v439

** Most of the anomaly is SMB

#+ATTR_LATEX: :width 0.9\textwidth
[[./fig/mankoff_2021_fig2.png]]

citet:mankoff_2021

** Fetch historical observations                        :noexport:

#+BEGIN_SRC bash
mkdir input
wget -nc  https://dataverse.geus.dk/api/access/datafile/:persistentId?persistentId=doi:10.22008/FK2/OHI23Z/NBMCEK -O ./input/mankoff_2021.csv

wget -nc https://dataverse.geus.dk/api/access/datafile/:persistentId?persistentId=doi:10.22008/FK2/OHI23Z/XQHQOB  -O ./input/mankoff_2021.nc
#+END_SRC

#+RESULTS:

** Compare Mankoff 2021 & Slater 2021
*** Figure                                                 :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:

#+BEGIN_SRC jupyter-python :results file :exports results :file ./fig/mankoff_v_slater.png
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
fig, (ax, ax2) = plt.subplots(nrows=2, figsize=(4,5))

kw = {'parse_dates':True, 'index_col':0}
S2021 = pd.read_csv('./input/GrIS_cumul_1994_2017_annual.csv', names=['Slater GrIS'], **kw)
M2021 = pd.read_csv('./input/mankoff_2021.csv', **kw)
M2021 = M2021['MB'].rename('Mankoff 2021').resample('YS').sum()['1990':'2022-12-31'].cumsum()

df = S2021.merge(M2021, left_index=True, right_index=True, how='outer')
df.index.name = 'Date'

for _ in df.columns: # extend by 1 year for plotting w/ 'step'
    df.loc[df[_].dropna().index[-1] + pd.offsets.DateOffset(years=1),_] = df[_].dropna().iloc[-1]

kw = {'drawstyle':'steps'}
(df['Slater GrIS']).diff().plot(ax=ax, **kw)
(df['Mankoff 2021']).diff().plot(ax=ax, **kw)
ax.set_ylabel('Annual\nmass change [Gt]')
(df['Mankoff 2021'].diff() - df['Slater GrIS'].diff()).plot(ax=ax, linestyle='--', color='k', alpha=0.5, **kw)

(df['Slater GrIS'] + df['Mankoff 2021'].loc['1994'].values).plot(ax=ax2, **kw)
df['Mankoff 2021'].plot(ax=ax2, **kw)
ax2.legend(['Slater 2021','Mankoff 2021'])
_ = ax2.set_ylabel('Cumulative\nmass change [Gt]')
axr = ax2.twinx()
axr.set_ylim(np.array(ax2.get_ylim()).astype(float)/-362)
_ = axr.set_ylabel('SLR [mm]')
#+END_SRC

#+RESULTS:
[[file:./fig/mankoff_v_slater.png]]


*** Text                                                   :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:

+ Upper panel: annual change (and difference between two products [dashed gray])
+ Lower panel: cumulative

** Greenlandic Peripheral glaciers

+ Need to determine where Greenlandic peripheral glaciers are in the citet:slater_2021 data
  + [ ] Greenland?
  + [ ] Glaciers?
+ Presumably they're included in the Greenland ice mass, because citet:slater_2021 uses GRACE, which cannot distinguish main ice from peripheral
+ citet:mankoff_2021 do not include peripheral glaciers, but can via a scaling factor
+ Note on previous slide - differences due to peripheral glacier treatment not detectable

** Greenlandic icebergs vs. (runoff & submarine melt)

*** Text                                                   :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.6
:END:

+ Surface melt and submarine melt should be introduced at the coast
+ Icebergs may melt farther away
+ However, icebergs in Greenland generally do not travel far
+ https://sentinel.esa.int/web/success-stories/-/greenland-iceberg-chart
+ http://polarportal.dk/en/sea-ice-and-icebergs/icebergs/

*** Figure                                                 :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.4
:END:

#+ATTR_LATEX: :height 0.8\textheight
[[./fig/Greenland-Iceberg-Chart.jpg]]

** Greenland mass loss by ROI [Gt yr^{-1}]

#+NAME: mb_roi
#+BEGIN_SRC jupyter-python :exports none :cache yes
import xarray as xr
fname = '/home/kdm/data/Mankoff_2021/203/MB_region.nc'
ds = xr.open_dataset(fname)
df_mb = ds['MB_ROI']\
    .sel({'time':slice('2000-01-01','2019-12-31')})\
    .resample({'time':'YS'}).sum()\
    .rename('Mass')\
    .mean(dim='time')\
    .to_dataframe()\
    .abs()
df_mb
#+END_SRC

#+RESULTS[(2023-01-27 07:26:53) 646cf553e2d9e39736442a79518f247aa28bb28a]: mb_roi
| region |    Mass |
|--------+---------|
| NE     |  24.798 |
| CE     | 1.40612 |
| SE     | 10.9155 |
| SW     | 23.1028 |
| CW     | 50.2505 |
| NW     | 59.8585 |
| NO     |  35.811 |

#+NAME: iceberg_roi
#+BEGIN_SRC jupyter-python :exports none :cache yes
import pandas as pd
fname = '/home/kdm/data/Mankoff_2020/ice/region_D.csv'
df_ice = pd.read_csv(fname, index_col=0, parse_dates=True)
df_ice = pd.DataFrame(df_ice['1990':'2020'].resample('YS').mean().mean())
df_ice.index.name = 'region'
df_ice.columns = ['Discharge']
df_ice
#+END_SRC

#+RESULTS[(2023-01-27 07:27:02) 67c3d0752fd16cd80ef00bbf168408a6e595a5b9]: iceberg_roi
| region | Discharge |
|--------+-----------|
| CE     |   74.5944 |
| CW     |   79.8808 |
| NE     |   25.0692 |
| NO     |   24.1457 |
| NW     |   99.2541 |
| SE     |   148.667 |
| SW     |   20.5418 |

#+BEGIN_SRC jupyter-python :exports none :eval no
### Warning: Run 1x in clean session. Compute intensive.
import xarray as xr
ds = xr.open_dataset('/home/kdm/data/Mankoff_2020/water/ice/MAR.nc',
                     chunks={'time':365, 'station':100})
ds = ds[['M2019_region','discharge']]
ds = ds.groupby('M2019_region')\
       .sum()

delayed_obj = ds.to_netcdf('tmp/MAR.nc', compute=False)
from dask.diagnostics import ProgressBar
with ProgressBar():
    results = delayed_obj.compute()
#+END_SRC

#+NAME: stream_roi
#+BEGIN_SRC jupyter-python :exports none :cache yes
import xarray as xr
ds = xr.open_dataset('./tmp/MAR.nc')

m3s_to_km3yr = 0.03155
df_stream = ds['discharge'].to_dataframe().unstack().T
df_stream.index = [_[1] for _ in df_stream.index]
df_stream = df_stream.resample('YS').mean() * m3s_to_km3yr
df_stream = df_stream.loc['1990-01-01':]

df_stream = pd.DataFrame(df_stream.mean())
df_stream.index.name = 'region'
df_stream.columns = ['Runoff']
df_stream
#+END_SRC

#+RESULTS[(2023-01-27 07:27:27) af0b8342115f1512478aac53eac87a5db1f49271]: stream_roi
| region |  Runoff |
|--------+---------|
| CE     | 56.8306 |
| CW     |  43.505 |
| NE     | 49.1332 |
| NO     | 40.4823 |
| NW     |  50.519 |
| SE     |  74.169 |
| SW     | 118.234 |

# COMBINE

#+BEGIN_SRC jupyter-python :noweb yes :exports results
kw = {'right_index':True, 'left_index':True}
df = df_mb.merge(df_ice, **kw).merge(df_stream, **kw)
df.loc['TOTAL'] = df.sum(axis='rows')
df.round()
#+END_SRC

#+RESULTS:
| region | Mass | Discharge | Runoff |
|--------+------+-----------+--------|
| NE     |   25 |        25 |     49 |
| CE     |    1 |        75 |     57 |
| SE     |   11 |       149 |     74 |
| SW     |   23 |        21 |    118 |
| CW     |   50 |        80 |     44 |
| NW     |   60 |        99 |     51 |
| NO     |   36 |        24 |     40 |
| TOTAL  |  206 |       472 |    433 |

+ Recall: \(\sim\)50 % discharge is submarine melt (runoff)
+ Spatial distribution doesn't matter (from previous slide)
+ Energy might?


** Greenland mass loss by ROI [%]
:PROPERTIES:
:ID:       20230127T114208
:END:

#+BEGIN_SRC jupyter-python :noweb yes :exports results
kw = {'right_index':True, 'left_index':True}
df = df_mb.merge(df_ice, **kw).merge(df_stream, **kw)

norm_df = df * (1/df.sum())
norm_df = (norm_df * 100).round()
norm_df.loc['TOTAL'] = norm_df.sum()
norm_df.sort_index()
#+END_SRC

#+RESULTS:
| region | Mass | Discharge | Runoff |
|--------+------+-----------+--------|
| CE     |    1 |        16 |     13 |
| CW     |   24 |        17 |     10 |
| NE     |   12 |         5 |     11 |
| NO     |   17 |         5 |      9 |
| NW     |   29 |        21 |     12 |
| SE     |    5 |        31 |     17 |
| SW     |   11 |         4 |     27 |
| TOTAL  |   99 |        99 |     99 |



** Greenland mass balance (annual)
:PROPERTIES:
:BEAMER_opt: shrink=8
:END:

#+BEGIN_SRC jupyter-python :exports results
import xarray as xr
df = xr.open_dataset('/home/kdm/data/Mankoff_2021/203/MB_region.nc')\
    .sum(dim='region')\
    .resample({'time':'YS'})\
    .sum()\
    .sel({'time':slice('1990-01-01','2099-12-31')})\
    ['MB']\
    .to_dataframe()

df.index = df.index.year
df
#+END_SRC

#+RESULTS:
| time |       MB |
|------+----------|
| 1990 | -133.815 |
| 1991 | -74.4873 |
| 1992 |  89.2746 |
| 1993 | -88.7964 |
| 1994 |     -112 |
| 1995 | -209.661 |
| 1996 |  135.049 |
| 1997 |  8.94794 |
| 1998 | -241.156 |
| 1999 | -45.9725 |
| 2000 | -75.7262 |
| 2001 | -24.6742 |
| 2002 | -140.389 |
| 2003 | -164.951 |
| 2004 | -163.611 |
| 2005 | -166.138 |
| 2006 | -237.157 |
| 2007 | -254.723 |
| 2008 | -197.735 |
| 2009 | -238.192 |
| 2010 | -371.977 |
| 2011 | -328.585 |
| 2012 | -424.435 |
| 2013 | -99.5643 |
| 2014 | -181.663 |
| 2015 | -212.821 |
| 2016 | -257.998 |
| 2017 | -100.593 |
| 2018 | -72.3407 |
| 2019 | -410.247 |
| 2020 | -171.684 |
| 2021 | -188.162 |
| 2022 |  75.5785 |


** Greenland mass balance (monthly)

*** All mass balance                                       :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:BEAMER_opt: shrink=8
:END:

#+BEGIN_SRC jupyter-python :exports results
import xarray as xr
df = xr.open_dataset('/home/kdm/data/Mankoff_2021/203/MB_region.nc')\
    .sum(dim='region')\ 
    .resample({'time':'MS'})\
    .sum()\
    .sel({'time':slice('1990-01-01','2099-12-31')})\
    ['MB']\
    .to_dataframe()

df.index = [_[:7] for _ in df.index.values.astype(str)]
df.head(25)
#+END_SRC

#+RESULTS:
|         |       MB |
|---------+----------|
| 1990-01 |  4.84136 |
| 1990-02 |  -5.5677 |
| 1990-03 | -6.32681 |
| 1990-04 |  5.02323 |
| 1990-05 |  20.3897 |
| 1990-06 | -78.3756 |
| 1990-07 | -154.283 |
| 1990-08 | -69.4715 |
| 1990-09 |  28.7042 |
| 1990-10 |  29.3712 |
| 1990-11 |  45.2992 |
| 1990-12 |  46.5813 |
| 1991-01 |  31.1833 |
| 1991-02 |  37.2381 |
| 1991-03 |  8.97941 |
| 1991-04 | -10.5305 |
| 1991-05 |  30.4264 |
| 1991-06 | -70.8015 |
| 1991-07 | -170.016 |
| 1991-08 |  -40.935 |
| 1991-09 |  9.29294 |
| 1991-10 |  51.1024 |
| 1991-11 |  6.88753 |
| 1991-12 |  42.6851 |
| 1992-01 |  44.6744 |



*** Negative mass balance                                  :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:BEAMER_opt: shrink=8
:END:

#+BEGIN_SRC jupyter-python :exports results
import xarray as xr
df = xr.open_dataset('/home/kdm/data/Mankoff_2021/203/MB_region.nc')\
    .sum(dim='region')\
    .resample({'time':'MS'})\
    .sum()\
    .sel({'time':slice('1990-01-01','2099-12-31')})\
    ['MB']\
    .to_dataframe()

df.index = [_[:7] for _ in df.index.values.astype(str)]
df[df < 0].head(25).fillna(0)
#+END_SRC

#+RESULTS:
|         |       MB |
|---------+----------|
| 1990-01 |        0 |
| 1990-02 |  -5.5677 |
| 1990-03 | -6.32681 |
| 1990-04 |        0 |
| 1990-05 |        0 |
| 1990-06 | -78.3756 |
| 1990-07 | -154.283 |
| 1990-08 | -69.4715 |
| 1990-09 |        0 |
| 1990-10 |        0 |
| 1990-11 |        0 |
| 1990-12 |        0 |
| 1991-01 |        0 |
| 1991-02 |        0 |
| 1991-03 |        0 |
| 1991-04 | -10.5305 |
| 1991-05 |        0 |
| 1991-06 | -70.8015 |
| 1991-07 | -170.016 |
| 1991-08 |  -40.935 |
| 1991-09 |        0 |
| 1991-10 |        0 |
| 1991-11 |        0 |
| 1991-12 |        0 |
| 1992-01 |        0 |


** Comments on previous slide

For monthly freshwater anomaly...
+ Doesn't make sense to estimate from total mass balance
  + Feb and March with mass loss (probably) comes from steady ice discharge and low snowfall
+ Better to estimate FW anomaly from stream discharge product
  + Need to define some monthly baseline
  + Then consider anomaly from baseline?

** Stream discharge: baseline [Gt/month] (1960--1989) 

#+BEGIN_SRC jupyter-python :exports results
import xarray as xr
ds = xr.open_dataset('./tmp/MAR.nc')

m3s_to_km3yr = 0.03155
df = ds['discharge'].to_dataframe().unstack().T
df.index = [_[1] for _ in df.index]
df = df.resample('MS').mean() * m3s_to_km3yr/12
baseline = df.loc['1960-01-01':'1989-12-31']

baseline = baseline.groupby(baseline.index.month).mean()
baseline.index.name = 'Month'

bb = baseline
bb['TOTAL'] = bb.sum(axis='columns')
bb.loc['TOTAL'] = bb.sum(axis='rows')

bb.round()
#+END_SRC

#+RESULTS:
| Month | CE | CW | NE | NO | NW | SE | SW | TOTAL |
|-------+----+----+----+----+----+----+----+-------|
|     1 |  0 |  0 |  0 |  0 |  0 |  0 |  0 |     0 |
|     2 |  0 |  0 |  0 |  0 |  0 |  0 |  0 |     0 |
|     3 |  0 |  0 |  0 |  0 |  0 |  0 |  0 |     0 |
|     4 |  0 |  0 |  0 |  0 |  0 |  0 |  0 |     0 |
|     5 |  1 |  1 |  0 |  0 |  0 |  1 |  2 |     5 |
|     6 |  9 |  7 |  4 |  3 |  5 | 11 | 16 |    54 |
|     7 | 20 | 15 | 20 | 15 | 18 | 24 | 42 |   155 |
|     8 | 12 |  9 |  7 |  5 |  9 | 18 | 26 |    86 |
|     9 |  2 |  1 |  0 |  0 |  1 |  5 |  5 |    12 |
|    10 |  0 |  0 |  0 |  0 |  0 |  0 |  0 |     1 |
|    11 |  0 |  0 |  0 |  0 |  0 |  0 |  0 |     0 |
|    12 |  0 |  0 |  0 |  0 |  0 |  0 |  0 |     0 |
| TOTAL | 43 | 33 | 31 | 24 | 33 | 60 | 91 |   314 |


** Stream discharge: anomaly [Gt/month] ((1990--2019)-base)

#+BEGIN_SRC jupyter-python :exports results
anomaly = df.loc['1990-01-01':'2019-12-31']

anomaly = anomaly.groupby(anomaly.index.month).mean()
anomaly.index.name = 'Month'

anomaly['TOTAL'] = anomaly.sum(axis='columns')
anomaly.loc['TOTAL'] = anomaly.sum(axis='rows')

(anomaly-baseline).round()
#+END_SRC

#+RESULTS:
| Month | CE | CW | NE | NO | NW | SE | SW | TOTAL |
|-------+----+----+----+----+----+----+----+-------|
|     1 | -0 |  0 |  0 |  0 |  0 |  0 | -0 |    -0 |
|     2 | -0 | -0 |  0 |  0 |  0 |  0 |  0 |     0 |
|     3 |  0 | -0 |  0 |  0 |  0 |  0 | -0 |     0 |
|     4 |  0 |  0 |  0 |  0 |  0 |  0 |  0 |     0 |
|     5 |  0 |  0 | -0 |  0 |  0 |  1 |  1 |     2 |
|     6 |  3 |  4 |  5 |  4 |  5 |  3 |  8 |    33 |
|     7 |  5 |  4 | 10 | 10 |  8 |  3 |  7 |    48 |
|     8 |  3 |  2 |  3 |  2 |  3 |  4 |  8 |    25 |
|     9 |  2 |  0 |  0 | -0 |  0 |  2 |  1 |     5 |
|    10 |  0 |  0 |  0 |  0 |  0 |  0 |  0 |     1 |
|    11 |  0 |  0 |  0 |  0 |  0 |  0 |  0 |     0 |
|    12 |  0 |  0 |  0 |  0 | -0 |  0 |  0 |     0 |
| TOTAL | 13 | 11 | 18 | 16 | 17 | 13 | 26 |   114 |


** Stream discharge: anomaly [%] [(anom - base)/base]

#+BEGIN_SRC jupyter-python :exports results
anomaly = df.loc['1990-01-01':'2019-12-31']

anomaly = anomaly.groupby(anomaly.index.month).mean()
anomaly.index.name = 'Month'

pct = ((anomaly-baseline)/baseline*100)
pct = pct[anomaly > 1]
pct = pct.drop(['TOTAL']).drop(columns=['TOTAL'])

pct.round()
#+END_SRC

#+RESULTS:
| Month |  CE |  CW |  NE |  NO |  NW |  SE |  SW |
|-------+-----+-----+-----+-----+-----+-----+-----|
|     1 | nan | nan | nan | nan | nan | nan | nan |
|     2 | nan | nan | nan | nan | nan | nan | nan |
|     3 | nan | nan | nan | nan | nan | nan | nan |
|     4 | nan | nan | nan | nan | nan | nan | nan |
|     5 | nan |  23 | nan | nan | nan |  53 |  49 |
|     6 |  38 |  61 | 114 | 126 |  89 |  31 |  54 |
|     7 |  24 |  28 |  51 |  64 |  47 |  14 |  17 |
|     8 |  21 |  22 |  48 |  47 |  37 |  20 |  31 |
|     9 | 115 |   5 | nan | nan | nan |  42 |  23 |
|    10 | nan | nan | nan | nan | nan | nan | nan |
|    11 | nan | nan | nan | nan | nan | nan | nan |
|    12 | nan | nan | nan | nan | nan | nan | nan |

** Summary

+ Some increase in solid ice discharge (10 %)
  + ...of which 50 % is submarine melt
+ Most increase in liquid runoff
  + Only summer in JJA

{{{SKIPLINE}}}

+ Can build baseline distribution maps for solid & liquid
+ Can build anomaly distribution maps for solid & liquid
+ Can provide annual or monthly solid and liquid forcing

* Antarctica
** IMBIE 2018

+ IMBIE citep:imbie_2018 has a longer records: 1992 through 2018 (and ongoing updates)
+ http://imbie.org/data-downloads/

{{{SKIPLINE}}}

However, IMBIE does not have ice shelf thinning or calving

** IMBIE 2018 vs Slater 2021

*** Text                                                   :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:

Bottom panel: Blue line is repeated from middle panel (Slater 2021)

*** Figure                                                 :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:

#+BEGIN_SRC bash
md5sum ~/data/IMBIE/* 
#+END_SRC

#+RESULTS:
| 0428261d001f8e3b8a18d43e6f29b629 | /home/kdm/data/IMBIE/imbie_dataset-2018_07_23.xlsx                    |
| 34d73176452df4039d42c668438fbcb5 | /home/kdm/data/IMBIE/imbie_dataset_greenland_dynamics-2020_02_28.xlsx |
  
#+BEGIN_SRC jupyter-python :exports results :results file :file ./fig/slater_v_imbie.png
import numpy as np
import pandas as pd
from datetime import datetime
from datetime import timedelta
import matplotlib.pyplot as plt

def convert_partial_year(number):
    year = int(number)
    d = timedelta(days=(number - year)*365)
    day_one = datetime(year,1,1)
    date = d + day_one
    return date.date()


imbie = pd.read_excel('~/data/IMBIE/imbie_dataset-2018_07_23.xlsx')\
    .rename(columns={'Cumulative ice mass change (Gt)':'IMBIE',
                     'Cumulative ice mass change uncertainty (Gt)':'IMBIE err'})\
    .drop(columns=['Cumulative sea level contribution (mm)',
                   'Cumulative sea level contribution uncertainty (mm)'])

imbie.index = pd.to_datetime([convert_partial_year(_) for _ in imbie['Year']])
imbie = imbie.drop(columns='Year')

# imbie = imbie.resample('1D').interpolate(dim='time').resample('YS').mean()
imbie = imbie.resample('YS').mean()



kw = {'parse_dates':True, 'index_col':0}
shelf_calving = pd.read_csv('./input/iceshelves_calving_cumul_1994_2017_annual.csv', names=['Ice Shelf Calving'], **kw)
shelf_thinning = pd.read_csv('./input/iceshelves_thinning_cumul_1994_2017_annual.csv', names=['Ice Shelf Thinning'], **kw)
AQ = pd.read_csv('./input/AIS_cumul_1994_2017_annual.csv', names=['Antarctica'], **kw)
kw = {'left_index':True, 'right_index':True, 'how':'outer'}
S2021 = shelf_calving.merge(shelf_thinning, **kw).merge(AQ, **kw)
S2021.index.name = 'Date'


df = imbie.merge(S2021, left_index=True, right_index=True, how='outer')
df.index.name = 'Date'

for _ in df.columns: # extend by 1 year for plotting w/ 'step'
    df.loc[df[_].dropna().index[-1] + pd.offsets.DateOffset(years=1),_] = df[_].dropna().iloc[-1]

fig, (ax, ax2, ax3) = plt.subplots(nrows=3, figsize=(4,7), sharex=True)
kw = {'drawstyle':'steps'}
(df['Antarctica']).diff().plot(ax=ax, **kw)
(df['IMBIE']).diff().plot(ax=ax, **kw)
ax.set_ylabel('Annual\nmass change [Gt]')
(df['IMBIE'] - df['Antarctica']).diff().plot(ax=ax, linestyle='--', color='k', alpha=0.5, **kw)

df[['Antarctica','IMBIE']]\
    .rename(columns={'Antarctica':'Slater 2021 (AQ)'})\
    .plot(ax=ax2, **kw)
_ = ax2.set_ylabel('Cumulative\nmass change [Gt]')
ax2r = ax2.twinx()
ax2r.set_ylim(np.array(ax2.get_ylim()).astype(float)/-362)
ax2r.set_ylabel('SLR [mm]')

xlim = ax2.get_xlim()

df['Total'] = df[['Antarctica','Ice Shelf Calving','Ice Shelf Thinning']].sum(axis='columns')
df['Ice Shelf (Combined)'] = df[['Ice Shelf Calving','Ice Shelf Thinning']].sum(axis='columns')
plt.rcParams.update({'legend.fontsize':8})
df[['Antarctica',
    'Ice Shelf Calving',
    'Ice Shelf Thinning',
    'Ice Shelf (Combined)',
    'Total',
    ]]\
    .dropna()\
    .plot(ax=ax3, **kw)
_ = ax3.set_ylabel('Cumulative\nfreshwater mass [Gt]')
_ = ax3.set_xlim(xlim)
#+END_SRC

#+ATTR_LATEX: :height 0.85\textheight
#+RESULTS:
[[file:./fig/slater_v_imbie.png]]

** Antarctic icebergs

+ [X] https://www.scp.byu.edu/data/iceberg/ citep:budge_2018
  + 1978 through 2018

#+ATTR_LATEX: :height 0.5\textheight
[[./fig/budge_2018.png]]    

+ [-] https://www.scar.org/resources/iceberg-database/ citep:orheim_2022
  + Biased by method: ship observations

** Iceberg distribution                                 :noexport:

#+BEGIN_SRC jupyter-python
import pandas as pd
import glob

root = '/home/kdm/data/Budge_2018/consol'
csvs = glob.glob(root + '/*.csv')

lon,lat = [],[]
for csv in csvs:
    df = pd.read_csv(csv, parse_dates=True, index_col='date')
    for i,c in enumerate(df.columns):
        if df[c].min() == df[c].max():
            continue
        if np.all(df[c] < 0):
            alat = df[c]
            alon = df[df.columns[i+1]]
            break

        lon = lon + list(alon)
        lat = lat + list(alat)

# plt.scatter(lon,lat)
pd.DataFrame(np.vstack((lon,lat)).T).to_csv('./tmp/lonlat.csv', index=False, header=None)

#+END_SRC


EPSG 3031
#+BEGIN_SRC bash
grass -c epsg:3031 ./G_AQ

eval $(m.proj -i input=tmp/lonlat.csv separator=comma,pipe |r.in.xyz input=- -sg)
g.region -pa n=$n s=-$n e=$(echo -1*$w|bc) w=$w res=100000 -s

m.proj -i input=tmp/lonlat.csv sep=comma,pipe | v.in.ascii input=- output=pts

# d.mon wx0
# d.vect pts

m.proj -i input=tmp/lonlat.csv sep=comma,pipe | r.in.xyz input=- output=bin method=n
r.mapcalc "bin10 = log(10,bin)"

# d.rast bin
#+END_SRC

EPSG 3031
#+BEGIN_SRC bash
grass -c epsg:4326 ./G_AQ

# g.region -pas res=0.125 s=-90 n=-45 e=-180 w=180
g.region -pas res=0.5 s=-90 n=-45 e=-180 w=180
v.in.ascii -n input=tmp/lonlat.csv sep=comma output=pts
cat tmp/lonlat.csv | sed 's/$/,1/' | r.in.xyz input=- separator=comma output=bin method=n
r.mapcalc "bin10 = log(10,bin)"
# d.rast bin
#+END_SRC

** FW forcing distribution

+ AQ solids
  + Spatial distribution of solid FW forcing may be unnecessary detail
  + Where icebergs are seen may be where they are not melting (observer bias)
  + Can distribute evenly around continent, or evenly where observed, or based on observation density
+ AQ liquids
  + Should be pegged to ice shelf edge
  + Do not have by shelf, only total for the continent

* Freshwater distribution mask
** Introduction

+ ModelE distributes Greenlandic melt via a fractional mask (sums to 1)
+ We can use the same mask to distribute the freshwater anomaly
+ However, the anomaly is distributed differently than the baseline
+ For example, Fig. 1 of citet:mankoff_2021 shows the SE (/included below/) has no net mass loss, and no change from <1990 baseline. However, SE should still have an annual baseline meltwater volume flow rate, because winter snowfall is offset by summer melt.

#+ATTR_LATEX: :height 3cm
[[./fig/mankoff_2021_fig1_orig.png]]

** Existing mask

+ Source : https://portal.nccs.nasa.gov/GISS_modelE/modelE_input_data/
+ 4x5 : =GLMELT_4X5.OCN.nc=
+ 2.5x2 : =GLMELT_144X90_gas.OCN.nc=

{{{SKIPLINE}}}

Land classification mask (could be useful when creating new mask)
+ 2.5x2 : =Z2HX2fromZ1QX1N.BS1.nc=
+ 1x1 : =OZ1QX1N.BS1.nc=
+ 1/60 : =etopo_ice_g1m.nc=

** Contents of GLMELT_144X90_gas.OCN.nc
:PROPERTIES:
:BEAMER_opt: shrink=6
:END:

#+BEGIN_SRC bash :exports results :results verbatim
ncdump dat/GLMELT_144X90_gas.OCN.nc | head -n40
echo "[...]"
#+END_SRC

#+RESULTS:
#+begin_example
netcdf GLMELT_144X90_gas.OCN {
dimensions:
	lon = 144 ;
	lat = 90 ;
variables:
	float lon(lon) ;
		lon:units = "degrees_east" ;
	float lat(lat) ;
		lat:units = "degrees_north" ;
	float mask(lat, lon) ;
data:

 lon = -178.75, -176.25, -173.75, -171.25, -168.75, -166.25, -163.75, 
    -161.25, -158.75, -156.25, -153.75, -151.25, -148.75, -146.25, -143.75, 
    -141.25, -138.75, -136.25, -133.75, -131.25, -128.75, -126.25, -123.75, 
    -121.25, -118.75, -116.25, -113.75, -111.25, -108.75, -106.25, -103.75, 
    -101.25, -98.75, -96.25, -93.75, -91.25, -88.75, -86.25, -83.75, -81.25, 
    -78.75, -76.25, -73.75, -71.25, -68.75, -66.25, -63.75, -61.25, -58.75, 
    -56.25, -53.75, -51.25, -48.75, -46.25, -43.75, -41.25, -38.75, -36.25, 
    -33.75, -31.25, -28.75, -26.25, -23.75, -21.25, -18.75, -16.25, -13.75, 
    -11.25, -8.75, -6.25, -3.75, -1.25, 1.25, 3.75, 6.25, 8.75, 11.25, 13.75, 
    16.25, 18.75, 21.25, 23.75, 26.25, 28.75, 31.25, 33.75, 36.25, 38.75, 
    41.25, 43.75, 46.25, 48.75, 51.25, 53.75, 56.25, 58.75, 61.25, 63.75, 
    66.25, 68.75, 71.25, 73.75, 76.25, 78.75, 81.25, 83.75, 86.25, 88.75, 
    91.25, 93.75, 96.25, 98.75, 101.25, 103.75, 106.25, 108.75, 111.25, 
    113.75, 116.25, 118.75, 121.25, 123.75, 126.25, 128.75, 131.25, 133.75, 
    136.25, 138.75, 141.25, 143.75, 146.25, 148.75, 151.25, 153.75, 156.25, 
    158.75, 161.25, 163.75, 166.25, 168.75, 171.25, 173.75, 176.25, 178.75 ;

 lat = -89, -87, -85, -83, -81, -79, -77, -75, -73, -71, -69, -67, -65, -63, 
    -61, -59, -57, -55, -53, -51, -49, -47, -45, -43, -41, -39, -37, -35, 
    -33, -31, -29, -27, -25, -23, -21, -19, -17, -15, -13, -11, -9, -7, -5, 
    -3, -1, 1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 
    35, 37, 39, 41, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61, 63, 65, 67, 69, 
    71, 73, 75, 77, 79, 81, 83, 85, 87, 89 ;

 mask =
  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
[...]
#+end_example


** Visualization of GLMELT_144X90_gas.OCN.nc

#+BEGIN_SRC jupyter-python :results verbatim :exports results
import xarray as xr
ds = xr.open_dataset('./dat/GLMELT_144X90_gas.OCN.nc')
_ = ds['mask'].plot()
#+END_SRC

#+ATTR_LATEX: :height 0.9\textheight
#+RESULTS:
[[file:./.ob-jupyter/4ae2299e0176cc83b7260b90276f2c9a1f22f10f.png]]


** Mask editing                                         :noexport:
*** Make mask QGIS compatible

+ Cannot do, currently, with 4x5.
  + https://lists.osgeo.org/pipermail/gdal-dev/2023-January/056767.html
  + https://github.com/OSGeo/gdal/pull/7113


#+BEGIN_SRC jupyter-python
import xarray as xr

fname = "GLMELT_144X90_gas.OCN.nc"
ds = xr.open_dataset("./dat/" + fname)

ds["crs"] = True
ds["crs"].attrs["grid_mapping_name"] = "latitude_longitude"

ds["mask"].attrs["grid_mapping"] = "crs"
ds["mask"].attrs["_FillValue"] = 0 # optional

ds.to_netcdf("./dat/" + fname[:-3] + ".crs.nc")
#+END_SRC


#+BEGIN_SRC bash
ncap2 -h -O -s 'crs=1B' ./dat/GLMELT_144X90_gas.OCN.nc ./dat/GLMELT_144X90_gas.OCN.v2.nc

ncatted -h -O \
    -a grid_mapping_name,crs,c,c,'latitude_longitude' \
    -a grid_mapping,mask,c,c,'crs' \
    -a _FillValue,mask,c,c,0 \
     ./dat/GLMELT_144X90_gas.OCN.v2.nc
#+END_SRC

#+RESULTS:


#+BEGIN_SRC bash :results verbatim
ncdump -chs ./dat/GLMELT_144X90_gas.OCN.crs.nc
#+END_SRC

#+RESULTS:
#+begin_example
netcdf GLMELT_144X90_gas.OCN.crs {
dimensions:
	lon = 144 ;
	lat = 90 ;
variables:
	float lon(lon) ;
		lon:_FillValue = NaNf ;
		lon:units = "degrees_east" ;
		lon:_Storage = "contiguous" ;
		lon:_Endianness = "little" ;
	float lat(lat) ;
		lat:_FillValue = NaNf ;
		lat:units = "degrees_north" ;
		lat:_Storage = "contiguous" ;
		lat:_Endianness = "little" ;
	float mask(lat, lon) ;
		mask:_FillValue = 0.f ;
		mask:grid_mapping = "crs" ;
		mask:_Storage = "contiguous" ;
		mask:_Endianness = "little" ;
	byte crs ;
		crs:grid_mapping_name = "latitude_longitude" ;
		crs:dtype = "bool" ;
		crs:_Storage = "contiguous" ;

// global attributes:
		:_NCProperties = "version=2,netcdf=4.8.1,hdf5=1.12.1" ;
		:_SuperblockVersion = 2 ;
		:_IsNetcdf4 = 1 ;
		:_Format = "netCDF-4" ;
}
#+end_example

*** Print locations (NH; 4x5)
#+BEGIN_SRC jupyter-python
import xarray as xr
ds = xr.open_dataset('./dat/GLMELT_4X5.OCN.nc')

ds = ds.where((ds['mask'] == 1) & (ds['lat'] > 0))
da_stacked = ds['mask'].stack(notnull=['lat','lon'])
dd = da_stacked[da_stacked.notnull()]
# print(dd)
df = pd.DataFrame([_ for _ in zip(dd['lat'].values,dd['lon'].values,dd.values)],
                  columns=['lat','lon','mask'])

# df.set_index(['lat','lon'])
df
#+END_SRC

#+RESULTS:
|   | lat |   lon | mask |
|---+-----+-------+------|
| 0 |  62 | -52.5 |    1 |
| 1 |  62 | -37.5 |    1 |
| 2 |  66 | -57.5 |    1 |
| 3 |  66 | -37.5 |    1 |
| 4 |  66 | -32.5 |    1 |
| 5 |  66 | -27.5 |    1 |
| 6 |  70 | -57.5 |    1 |
| 7 |  70 | -22.5 |    1 |
| 8 |  74 | -57.5 |    1 |
| 9 |  74 | -17.5 |    1 |


*** Print locations (NH; 2.5x2)
#+BEGIN_SRC jupyter-python
import xarray as xr
melt = xr.open_dataset('./dat/GLMELT_4X5.OCN.nc')
cl = xr.open_dataset('./dat/Z2HX2fromZ1QX1N.BS1.nc')
ds = melt.merge(cl)

ds = ds.where((ds['mask'] == 1) & (ds['lat'] > 0))

st = ds.stack(notnull=['lat','lon'])
da_stacked = ds['mask'].stack(notnull=['lat','lon'])
dd = da_stacked[da_stacked.notnull()]
# print(dd)
df = pd.DataFrame([_ for _ in zip(dd['lat'].values,dd['lon'].values,dd.values)],
                  columns=['lat','lon','mask'])

# df.set_index(['lat','lon'])
df
#+END_SRC

#+RESULTS:
|   | lat |   lon | mask |
|---+-----+-------+------|
| 0 |  62 | -52.5 |    1 |
| 1 |  62 | -37.5 |    1 |
| 2 |  66 | -57.5 |    1 |
| 3 |  66 | -37.5 |    1 |
| 4 |  66 | -32.5 |    1 |
| 5 |  66 | -27.5 |    1 |
| 6 |  70 | -57.5 |    1 |
| 7 |  70 | -22.5 |    1 |
| 8 |  74 | -57.5 |    1 |
| 9 |  74 | -17.5 |    1 |


** New mask creation                                    :noexport:
*** 100 km buffer around Greenland (raw)                :noexport:

+ Generate on 1/8 ° (lat,lon) grid grid
+ Can then be resampled as needed

#+BEGIN_SRC bash
grass -c epsg:4326 ./G
g.region n=90 s=-90 w=-180 e=180 res=0.125 -pas # 1/8 = 0.125

mkdir -p tmp
ogr2ogr -f KML tmp/M2019.kml ${DATADIR}/Mouginot_2019/Greenland_Basins_PS_v1.4.2.shp


# d.mon wx0
# d.vect M2019

v.in.ogr input=tmp/M2019.kml output=M2019
# db.select table=M2019 | head

v.db.addcolumn map=M2019 columns="REGION, INT"
# Encode using clock face numerics
db.execute sql='UPDATE M2019 SET REGION=1 where SUBREGION1 = "NE"'
db.execute sql='UPDATE M2019 SET REGION=12 where SUBREGION1 = "NO"'
db.execute sql='UPDATE M2019 SET REGION=11 where SUBREGION1 = "NW"'
db.execute sql='UPDATE M2019 SET REGION=3 where SUBREGION1 = "CE"'
db.execute sql='UPDATE M2019 SET REGION=9 where SUBREGION1 = "CW"'
db.execute sql='UPDATE M2019 SET REGION=5 where SUBREGION1 = "SE"'
db.execute sql='UPDATE M2019 SET REGION=7 where SUBREGION1 = "SW"'
v.to.rast input=M2019 output=M2019 type=area use=attr attribute_column=REGION

# d.mon wx0
# d.rast M2019

r.grow.distance -m input=M2019 value=M2019_grow distance=distance metric=geodesic

# r.mapcalc "ocean5km = if((distance > 0) & (distance < 50000), M2019_grow, null())"
r.mapcalc "ocean_gl = if((distance > 0) & (distance < 100000), M2019_grow, null())"

# r.out.gdal format=netCDF input=ocean5km output=tmp/ocean5km.nc
r.out.gdal format=netCDF input=ocean_gl output=tmp/ocean_gl.nc
#+END_SRC


*** 500 km around Antarctic shelves

#+BEGIN_SRC bash
# grass ./G/PERMANENT

ogr2ogr -f KML tmp/aq.kml ${DATADIR}/NSIDC/NSIDC-0709.002/1992.02.07/IceBoundaries_Antarctica_v02.shp
v.in.ogr input=tmp/aq.kml output=boundary

ogr2ogr -f KML tmp/shelf.kml ${DATADIR}/NSIDC/NSIDC-0709.002/1992.02.07/IceShelf_Antarctica_v02.shp
# v.in.ogr input=tmp/shelf.kml output=shelf_all
# v.db.droprow input=shelf_all where='Name == "Filchner" OR Name == "Ross_West" OR Name == "Ross_East"' output=shelf
v.in.ogr input=tmp/shelf.kml output=shelf

v.to.rast input=shelf output=shelf type=area use=val val=1 # attr attribute_column=REGION
v.to.rast input=boundary output=boundary type=area use=val val=1

r.grow.distance -m input=shelf value=shelf_grow distance=distance_aq metric=geodesic

r.mapcalc "ocean_aq = if((distance_aq > 0) & (distance_aq < 500000) & isnull(boundary) & (y() > -80), shelf_grow, null())"
r.out.gdal format=netCDF input=ocean_aq output=tmp/ocean_aq.nc
#+END_SRC

*** Build Greenland mask with scaled distribution       :noexport:

+ See slides above for [[id:20230127T114208][Greenland mass loss by ROI [%]​]]

WARNING: This spreads the distribution per sector over the number of grid cells. Because I'm working on my own map of Greenland at high res, some of these grid cells will be land-cells in ModelE. The relative number of land cells per sector should be similar between sectors (large sectors means long coastline meaning many land cells, vs. small sector short coast few cells), meaning this error may not be significant to final results.

#+BEGIN_SRC jupyter-python
import numpy as np
import xarray as xr

aq = xr.open_dataset('./tmp/ocean_aq.nc')

ds = xr.open_dataset('./tmp/ocean_gl.nc')
ds['lon'].attrs['units'] = 'degrees_east'
ds['lat'].attrs['units'] = 'degrees_north'

# record the RIO for each cell
ROI = np.empty(ds['Band1'].data.shape, dtype='U2')
b1 = ds['Band1'].values.astype(int)
ROI[b1 == 12] = 'NO' # cloc face
ROI[b1 == 1] = 'NE'
ROI[b1 == 3] = 'CE'
ROI[b1 == 5] = 'SE'
ROI[b1 == 7] = 'SW'
ROI[b1 == 9] = 'CW'
ROI[b1 == 11] = 'NW'
ROI[b1 == b1[0,0]] = ''
ds['ROI'] = (('lat','lon'), ROI)
ds['ROI'].attrs['ROI_source'] = 'Mouginot /et al./ (2019); https://doi.org/10.7280/D1WT11'

ds['ones'] = (ds['Band1'].notnull()+aq['Band1'].notnull()).astype(np.int32)
ds['ones'].attrs['description'] = 'Grid cells with freshwater runoff, submarine melt, or iceberg forcing'
ds = ds.drop_vars('Band1')

# ds['base'] = ds['ones']
# ds['base'].attrs['description'] = 'Baseline freshwater runoff, submarine melt, or iceberg forcing, scaled by sector contribution'

# ds['base_solid'] = ds['ones']
# ds['base_solid'].attrs['description'] = 'Baseline iceberg forcing, scaled by sector contribution'

# ds['base_liquid'] = ds['ones']
# ds['base_liquid'].attrs['description'] = 'Baseline freshwater runoff and submarine melt scaled by sector contribution'

ds['anom'] = ds['ones'].astype(np.float32)
ds['anom'].attrs['description'] = 'Anomaly freshwater runoff, submarine melt, or iceberg forcing, scaled by sector contribution'
contrib = {'CE':1, 'CW':24, 'NO':12, 'NE':17, 'NW':29, 'SE':5, 'SW':11}
ds['anom'].attrs['distribution_pct'] = str(contrib)
# ds['anom'] = ds['anom'].where(ds['ROI'] != 'CE', other=(1  / ds['ones'].where(ds['ROI'] == 'CE').sum().data))
# ds['anom'] = ds['anom'].where(ds['ROI'] != 'CW', other=(24 / ds['ones'].where(ds['ROI'] == 'CW').sum().data))
# ds['anom'] = ds['anom'].where(ds['ROI'] != 'NO', other=(12 / ds['ones'].where(ds['ROI'] == 'NO').sum().data))
# ds['anom'] = ds['anom'].where(ds['ROI'] != 'NE', other=(17 / ds['ones'].where(ds['ROI'] == 'NE').sum().data))
# ds['anom'] = ds['anom'].where(ds['ROI'] != 'NW', other=(29 / ds['ones'].where(ds['ROI'] == 'NW').sum().data))
# ds['anom'] = ds['anom'].where(ds['ROI'] != 'SE', other=(5  / ds['ones'].where(ds['ROI'] == 'SE').sum().data))
# ds['anom'] = ds['anom'].where(ds['ROI'] != 'SW', other=(11 / ds['ones'].where(ds['ROI'] == 'SW').sum().data))
for k,v in contrib.items():
    ds['anom'] = ds['anom'].where(ds['ROI'] != k, other=(v  / ds['ones'].where(ds['ROI'] == k).sum().data))

ds['anom_solid'] = ds['ones'].astype(np.float32)
ds['anom_solid'].attrs['description'] = 'Anomaly iceberg forcing, scaled by sector contribution'
contrib = {'CE':16, 'CW':17, 'NO':5, 'NE':5, 'NW':21, 'SE':31, 'SW':4}
ds['anom_solid'].attrs['distribution_pct'] = str(contrib)
for k,v in contrib.items():
    ds['anom_solid'] = ds['anom_solid'].where(ds['ROI'] != k, other=(v  / ds['ones'].where(ds['ROI'] == k).sum().data))

ds['anom_liquid'] = ds['ones'].astype(np.float32)
ds['anom_liquid'].attrs['description'] = 'Anomaly freshwater runoff and submarine melt scaled by sector contribution'
contrib = {'CE':13, 'CW':10, 'NO':11, 'NE':9, 'NW':12, 'SE':17, 'SW':27}
ds['anom_liquid'].attrs['distribution_pct'] = str(contrib)
for k,v in contrib.items():
    ds['anom_liquid'] = ds['anom_liquid'].where(ds['ROI'] != k, other=(v  / ds['ones'].where(ds['ROI'] == k).sum().data))

ds['crs'] = True
ds['crs'].attrs['grid_mapping_name'] = 'latitude_longitude'

for v in ds.data_vars:
    ds[v].attrs['grid_mapping'] = 'crs'
    if (v != 'crs') and (v != 'ROI'):
        ds[v].attrs['_FillValue'] = 0

ds.attrs = {}        
ds.attrs['Creator'] = 'Ken Mankoff'
ds.attrs['email'] = 'ken.mankoff@nasa.gov'
        
ds.to_netcdf('./dat/fw.nc')
print(ds)
#+END_SRC

#+RESULTS:
#+begin_example
<xarray.Dataset>
Dimensions:      (lat: 1440, lon: 2880)
Coordinates:
  ,* lat          (lat) float64 -89.94 -89.81 -89.69 -89.56 ... 89.69 89.81 89.94
  ,* lon          (lon) float64 -179.9 -179.8 -179.7 -179.6 ... 179.7 179.8 179.9
Data variables:
    crs          bool True
    ROI          (lat, lon) <U2 '' '' '' '' '' '' '' '' ... '' '' '' '' '' '' ''
    ones         (lat, lon) int32 0 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0
    anom         (lat, lon) float32 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0
    anom_solid   (lat, lon) float32 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0
    anom_liquid  (lat, lon) float32 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0
Attributes:
    Creator:  Ken Mankoff
    email:    ken.mankoff@nasa.gov
#+end_example

*** NOT USED                                            :noexport:

#+BEGIN_SRC jupyter-python
ds = xr.Dataset()

step = 1/60
ds['lon'] = np.arange(-180 + (step/2),180, step, dtype=np.float64)
ds['lon'].attrs['units'] = 'degrees_north'

ds['lat'] = np.arange(-90 + (step/2), 90, step, dtype=np.float64)
ds['lat'].attrs['units'] = 'degrees_east'

ds['crs'] = True
ds['crs'].attrs['grid_mapping_name'] = 'latitude_longitude'

ds['ROI'] = (('lon','lat'), np.zeros((ds['lon'].size, ds['lat'].size), dtype='U2'))
# ds['ROI'].attrs['_FillValue'] = ''
ds['ROI'].attrs['grid_mapping'] = 'crs'
ds['ROI'].attrs['ROI_source'] = 'Mouginot /et al./ (2019); https://doi.org/10.7280/D1WT11'

## Example: Can set fields with:
# ds['ROI'][:,np.where(ds['lat'] == 80)[0][0]:np.where(ds['lat'] == 90)[0][0]] = 'NO'
## Let's create a small function to help with that.

def lati(val): return np.where(ds['lat'] == val)[0][0] # lat index
def loni(val): return np.where(ds['lon'] == val)[0][0]
# use like: ds['ROI'][:,lati(80):lati(90)+1] = 'NO'

ds['ROI'][loni(ds.isel(27,38] = 'SW'
# ds['ROI'][ds.isel(27,38] = 'SW'
# ds['region'][26,39] = 'SW'
# ds['region'][25,40] = 'SW'

# ds['region'][27,38] = 'SE'
# ds['region'][27,38] = 'SE'
# ds['region'][27,38] = 'SE'


ds.attrs['Creator'] = 'Ken Mankoff'
ds.attrs['email'] = 'ken.mankoff@nasa.gov'
ds.to_netcdf('icesheet_runoff_mask.nc')
print(ds)
#+END_SRC

#+RESULTS:
#+begin_example
<xarray.Dataset>
Dimensions:  (lon: 2881, lat: 1441)
Coordinates:
  ,* lon      (lon) float64 -180.0 -179.9 -179.8 -179.6 ... 179.8 179.9 180.0
  ,* lat      (lat) float64 -90.0 -89.88 -89.75 -89.62 ... 89.62 89.75 89.88 90.0
Data variables:
    crs      bool True
    ROI      (lon, lat) <U2 '' '' '' '' '' '' '' ... 'NO' 'NO' 'NO' '' '' ''
Attributes:
    Creator:  Ken Mankoff
    email:    ken.mankoff@nasa.gov
#+end_example


** Greenland mask

+ =ones= : All 1 within 100 km of Greenland coast
+ =anom= : MB anomaly by ROI
+ =anom_liquid= SMB anomaly by ROI
+ =anom_solid= Discharge anomaly by ROI

** Antarctic mask ???

Even distribution w/in 500 km of coast

+ Solid discharge at ice shelf fronts
  + Scaled by ice shelf area??
+ Ice shelf melting at ice shelf fronts
  + Scaled by ice shelf area??

{{{SKIPLINE}}}

Doesn't reflect reality - most of the mass loss from small shelves, not Ross and Filchner-Ronne (mass gain).
+ Exclude Ross and Filchner-Ronne?

{{{SKIPLINE}}}

citet:NSIDC_0709,rignot_2013
See https://nsidc.org/data/nsidc-0709


** New mask contents
:PROPERTIES:
:BEAMER_opt: shrink=6
:END:

[[./fig/panoply_fw.nc.png]]

#+BEGIN_SRC bash :exports none :results verbatim
ncdump dat/fw.nc | head -n40
echo "[...]"
#+END_SRC

#+RESULTS:
#+begin_example
netcdf fw {
dimensions:
	lat = 1440 ;
	lon = 2880 ;
variables:
	byte crs ;
		crs:grid_mapping_name = "latitude_longitude" ;
		crs:grid_mapping = "crs" ;
		crs:dtype = "bool" ;
	double lat(lat) ;
		lat:_FillValue = NaN ;
		lat:standard_name = "latitude" ;
		lat:long_name = "latitude" ;
		lat:units = "degrees_north" ;
	double lon(lon) ;
		lon:_FillValue = NaN ;
		lon:standard_name = "longitude" ;
		lon:long_name = "longitude" ;
		lon:units = "degrees_east" ;
	string ROI(lat, lon) ;
		ROI:ROI_source = "Mouginot /et al./ (2019); https://doi.org/10.7280/D1WT11" ;
		ROI:grid_mapping = "crs" ;
	int ones(lat, lon) ;
		ones:_FillValue = 0 ;
		ones:description = "Grid cells with freshwater runoff, submarine melt, or iceberg forcing" ;
		ones:grid_mapping = "crs" ;
	float anom(lat, lon) ;
		anom:_FillValue = 0.f ;
		anom:description = "Anomaly freshwater runoff, submarine melt, or iceberg forcing, scaled by sector contribution" ;
		anom:distribution_pct = "{\'CE\': 1, \'CW\': 24, \'NO\': 12, \'NE\': 17, \'NW\': 29, \'SE\': 5, \'SW\': 11}" ;
		anom:grid_mapping = "crs" ;
	float anom_solid(lat, lon) ;
		anom_solid:_FillValue = 0.f ;
		anom_solid:description = "Anomaly iceberg forcing, scaled by sector contribution" ;
		anom_solid:distribution_pct = "{\'CE\': 16, \'CW\': 17, \'NO\': 5, \'NE\': 5, \'NW\': 21, \'SE\': 31, \'SW\': 4}" ;
		anom_solid:grid_mapping = "crs" ;
	float anom_liquid(lat, lon) ;
		anom_liquid:_FillValue = 0.f ;
		anom_liquid:description = "Anomaly freshwater runoff and submarine melt scaled by sector contribution" ;
		anom_liquid:distribution_pct = "{\'CE\': 13, \'CW\': 10, \'NO\': 11, \'NE\': 9, \'NW\': 12, \'SE\': 17, \'SW\': 27}" ;
[...]
#+end_example



** New mask visualization

#+BEGIN_SRC jupyter-python :results verbatim :exports results
import xarray as xr
ds = xr.open_dataset('./dat/fw.nc')
_ = (ds['anom']).sel({'lat':slice(50,90),'lon':slice(-90,0)}).plot()
# _ = (1E2*ds['anom_liquid']).plot()
# _ = (1E2*ds['anom_solid']).plot()
#+END_SRC

#+ATTR_LATEX: :height 0.9\textheight
#+RESULTS:
[[file:./.ob-jupyter/0c5e574a5639bd4ead38ebfe27bfc7ca2a1e11d0.png]]

* Summary
** Questions & To Do                                    :noexport:

+ [ ] Updated baseline mask
  + [ ] Include N. Greenland
  + [ ] Treat spatial variability
  + [ ] Separate (liquid runoff & submarine melt) v. solid discharge
+ [ ] Anomaly: determine regional distribution of
  + [ ] Liquid runoff & submarine melt
  + [ ] Solid ice discharge
+ [ ] Build anomaly distribution masks for each of these

* Appendix                                            :B_appendix:
:PROPERTIES:
:BEAMER_env: appendix
:END:
** References
:PROPERTIES:
:BEAMER_opt: allowframebreaks,label=
:END:

#+LATEX_HEADER_EXTRA: \renewcommand*{\bibfont}{\small}
\printbibliography[heading=none]

** About This Document
# :PROPERTIES:
# :BEAMER_opt: shrink=10
# :END:

This document is an Emacs Org Mode plain-text file with code and text
embedded. If you are viewing:
+ A PDF, HTML, or DOC file, then it was generated by exporting from Org. Not all of the Org parts (code, results, comments, etc.) were exported. The Org source file is available upon request, and may be embedded in the PDF. You can access files embedded in PDF files with from within your PDF viewer.
+ A file with an ~org~ extension in something other than Emacs, then you are seeing the canonical version and the full source, but without any syntax highlighting, document structure, or the ability to execute the code blocks.
+ An ~Org~ file within Emacs, then this is the canonical version. You should be able to fully interact and reproduce the contents of this document, although it may require 3rd-party applications (Python, etc.) and a similar Emacs configuration. This is available upon request.

* LaTeX Header                                          :noexport:
** Beamer

#+STARTUP: beamer
#+LaTeX_CLASS_OPTIONS: [presentation, smaller, compress, aspectratio=169]
#+COLUMNS: %45ITEM %10BEAMER_env(Env) %10BEAMER_act(Act) %4BEAMER_col(Col) %8BEAMER_opt(Opt)
#+PROPERTY: BEAMER_col_ALL 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 0.0 :ETC

*** Title Page

#+BEAMER_HEADER: \subtitle{GL \& AQ}
#+BEAMER_HEADER: \institute[]{NASA GISS}

#+BEAMER_HEADER: \titlegraphic{\includegraphics[height=1.0cm]{/home/kdm/Documents/templates/logos/NASA.png}}

# #+BEAMER_HEADER: \logo{\includegraphics[height=1.0cm]{/home/kdm/Documents/templates/logos/NASA.png}}

*** Theme

#+BEAMER_THEME: Frankfurt
#+BEAMER_COLOR_THEME: seagull

#+BEAMER_HEADER: \setbeamertemplate{navigation symbols}{}

#+BEAMER_HEADER: \setbeamercolor*{block title alerted}{bg=yellow!50}
#+BEAMER_HEADER: \setbeamercolor*{block body alerted}{bg=yellow!30}
#+BEAMER_HEADER: \setbeamertemplate{blocks}[rounded][shadow=true]

#+BEAMER_HEADER: \setbeamercovered{transparent=30} % preview hidden content
# #+BEAMER_HEADER: \setbeamercovered{invisible}


#+BEAMER_HEADER: \setbeamertemplate{footline}{}

#+BEAMER_HEADER: \setbeamertemplate{frametitle}{%
#+BEAMER_HEADER:   \nointerlineskip
#+BEAMER_HEADER:     \begin{beamercolorbox}[sep=0.1cm,wd=\paperwidth,leftskip=.2cm,rightskip=0cm]{frametitle}%
#+BEAMER_HEADER:       \usebeamerfont{frametitle}\usebeamercolor[fg]{frametitle}\insertframetitle\\
#+BEAMER_HEADER:       \usebeamerfont{framesubtitle}\usebeamercolor[fg]{framesubtitle}\insertframesubtitle
#+BEAMER_HEADER:     \end{beamercolorbox}%
#+BEAMER_HEADER: }

#+BEAMER_HEADER: \usepackage{tikz}
#+BEAMER_HEADER: \addtobeamertemplate{frametitle}{}{%
#+BEAMER_HEADER: \begin{tikzpicture}[remember picture,overlay]
#+BEAMER_HEADER:   \node[anchor=south east,yshift=0pt] at (current page.south east) {\includegraphics[height=1cm]{/home/kdm/Documents/templates/logos/NASA.png}};
#+BEAMER_HEADER: \end{tikzpicture}\vspace{-0.4cm}}

#+BEAMER_HEADER: \addtobeamertemplate{frametitle}{}{\tikz[overlay, remember picture] \node[anchor=south west,yshift=1pt] at (current page.south west){{\tiny\textcolor{gray}{\insertframenumber}}};}

# #+BEAMER_HEADER: \setbeamerfont{headline}{size=\small}
#+BEAMER_HEADER: \setbeamerfont{frametitle}{size=\Large}
# \tiny \scriptsize \footnotesize \small \normalsize \large \Large \huge \Huge

# (setq org-latex-listings nil)

# #+INCLUDE: "./listings.org"
# #+LaTeX: \setbeamercolor*{block title verbatim}{bg=yellow!50}
# #+LaTeX: \setbeamercolor*{block body verbatim}{bg=yellow!30}

*** COMMENT Presenter Notes


%% Presenter Notes
#+BEAMER_HEADER: \usepackage{pgfpages}
#+BEAMER_HEADER: \setbeameroption{show notes on second screen}
# #+BEAMER_HEADER: \setbeameroption{show notes on second screen=left}
# #+BEAMER_HEADER: \setbeamertemplate{note page}[plain]

# #+BEAMER_HEADER: \usepackage{handoutWithNotes}
# #+BEAMER_HEADER: \pgfpagesuselayout{4 on 1 with notes}[a4paper,border shrink=5mm]

*** Other

#+BEAMER_HEADER: \usepackage{multimedia}
#+BEAMER_HEADER: \usepackage{lxfonts}
#+BEAMER_HEADER: \usefonttheme{professionalfonts}

#+BEAMER_HEADER: \newcommand\bgimage[1]{%
#+BEAMER_HEADER: \begin{backgroundblock}{-1mm}{0mm}
#+BEAMER_HEADER: \includegraphics[height=\paperheight]{#1}
#+BEAMER_HEADER: \end{backgroundblock}}

#+BEAMER_HEADER: \newcommand\bgimagewide[1]{%
#+BEAMER_HEADER: \begin{backgroundblock}{-1mm}{15mm}
#+BEAMER_HEADER: \includegraphics[width=\paperwidth]{#1}
#+BEAMER_HEADER: \end{backgroundblock}}

#+BEAMER_HEADER: \usepackage[outline]{contour}
#+BEAMER_HEADER: \usepackage[absolute,overlay]{textpos}
#+BEAMER_HEADER: \newcommand\footertext[1]{%
#+BEAMER_HEADER:   \begin{textblock*}{\paperwidth}(1em,0.95\paperheight)
#+BEAMER_HEADER:     \contour{red}\protect\textcolor{black}{\small{#1}}
#+BEAMER_HEADER:   \end{textblock*}}

# #+LATEX_HEADER: \newcommand*{\TakeFourierOrnament}[1]{{%
# #+LATEX_HEADER: \fontencoding{U}\fontfamily{futs}\selectfont\char#1}}
# #+LATEX_HEADER: \newcommand*{\danger}{\TakeFourierOrnament{66}}
#+LATEX_HEADER: \usepackage{fontawesome}

** References

#+LATEX_HEADER_EXTRA:%\usepackage[bibstyle=authoryear,firstinits=true,maxbibnames=99]{biblatex}
#+LATEX_HEADER_EXTRA: \usepackage[hyperref=true,
#+LATEX_HEADER_EXTRA:             %sorting=none, 
#+LATEX_HEADER_EXTRA:             sorting=nyt,
#+LATEX_HEADER_EXTRA:             %style=numeric, 
#+LATEX_HEADER_EXTRA:             style=authoryear,
#+LATEX_HEADER_EXTRA:             %defernumbers=true, 
#+LATEX_HEADER_EXTRA:             firstinits=true, 
#+LATEX_HEADER_EXTRA:             uniquename=false,
#+LATEX_HEADER_EXTRA:             uniquelist=false,
#+LATEX_HEADER_EXTRA:             %uniquelist=minyear,
#+LATEX_HEADER_EXTRA:             maxnames=99, 
#+LATEX_HEADER_EXTRA:             backend=biber,
#+LATEX_HEADER_EXTRA:             bibenconding=utf8,
#+LATEX_HEADER_EXTRA:             maxcitenames=2]{biblatex}
#+LATEX_HEADER_EXTRA:\addbibresource{/home/kdm/Documents/Papers/library.bib}
#+LATEX_HEADER_EXTRA:\addbibresource{/home/kdm/Documents/Papers/software.bib}
#+LATEX_HEADER_EXTRA:\addbibresource{/home/kdm/Documents/Papers/data.bib}
#+LATEX_HEADER_EXTRA: \renewbibmacro{in:}{}
#+LATEX_HEADER_EXTRA: \renewcommand*{\bibfont}{\footnotesize}

# biber <texfile><.NOEXT> --output_format bibtex

#+LATEX_HEADER_EXTRA: \usepackage{xpatch}
#+LATEX_HEADER_EXTRA: \xpatchbibmacro{name:andothers}{%
#+LATEX_HEADER_EXTRA:   \bibstring{andothers}%
#+LATEX_HEADER_EXTRA: }{%
#+LATEX_HEADER_EXTRA:   \bibstring[\emph]{andothers}%
#+LATEX_HEADER_EXTRA: }{}{}

# http://tex.stackexchange.com/a/5779/360
#+LATEX_HEADER_EXTRA: % Don't print URL if DOI field exists
#+LATEX_HEADER_EXTRA: \DeclareFieldFormat{url}{%
#+LATEX_HEADER_EXTRA:   \iffieldundef{doi}{%
#+LATEX_HEADER_EXTRA:     \mkbibacro{URL}\addcolon\space\url{#1}%
#+LATEX_HEADER_EXTRA:   }{%
#+LATEX_HEADER_EXTRA:   }%
#+LATEX_HEADER_EXTRA: }
#+LATEX_HEADER_EXTRA: % Don't print URL if DOI field exists
#+LATEX_HEADER_EXTRA: \DeclareFieldFormat{urldate}{%
#+LATEX_HEADER_EXTRA:   \iffieldundef{doi}{%
#+LATEX_HEADER_EXTRA:     \mkbibparens{\bibstring{urlseen}\space#1}%
#+LATEX_HEADER_EXTRA:   }{%
#+LATEX_HEADER_EXTRA:   }%
#+LATEX_HEADER_EXTRA: }

#+LATEX_HEADER_EXTRA: \renewbibmacro*{journal+issuetitle}{%
#+LATEX_HEADER_EXTRA: \usebibmacro{journal}%
#+LATEX_HEADER_EXTRA: \setunit*{\addspace}%
#+LATEX_HEADER_EXTRA: \iffieldundef{series}
#+LATEX_HEADER_EXTRA: {}
#+LATEX_HEADER_EXTRA: {\newunit
#+LATEX_HEADER_EXTRA: \printfield{series}%
#+LATEX_HEADER_EXTRA: \setunit{\addspace}}%
#+LATEX_HEADER_EXTRA: \usebibmacro{issue+date}%
#+LATEX_HEADER_EXTRA: \setunit{\addcomma\space}%
#+LATEX_HEADER_EXTRA: \usebibmacro{volume+number+eid}%
#+LATEX_HEADER_EXTRA: \setunit{\addcolon\space}%
#+LATEX_HEADER_EXTRA: \usebibmacro{issue}%
#+LATEX_HEADER_EXTRA: \newunit}

#+LATEX_HEADER_EXTRA: \newbibmacro*{issue+date}{%
#+LATEX_HEADER_EXTRA: \iffieldundef{issue}
#+LATEX_HEADER_EXTRA: {. \usebibmacro{date}}
#+LATEX_HEADER_EXTRA: {\printfield{issue}%
#+LATEX_HEADER_EXTRA: \setunit*{\addspace}%
#+LATEX_HEADER_EXTRA: \usebibmacro{date}}%
#+LATEX_HEADER_EXTRA: \newunit}

#+LATEX_HEADER_EXTRA: \renewbibmacro*{volume+number+eid}{%
#+LATEX_HEADER_EXTRA: \printfield{volume}%
#+LATEX_HEADER_EXTRA: \setunit*{\addnbspace}% NEW (optional); there's also #+LATEX_HEADER_EXTRA: \addnbthinspace
#+LATEX_HEADER_EXTRA: \printfield{number}%
#+LATEX_HEADER_EXTRA: \setunit{\addcomma\space}%
#+LATEX_HEADER_EXTRA: \printfield{eid}}
#+LATEX_HEADER_EXTRA: \DeclareFieldFormat[article]{number}{\mkbibparens{#1}}

#+LATEX_HEADER_EXTRA: \DeclareFieldFormat{pages}{#1}

** Hyperref
#+LATEX_HEADER_EXTRA:  %\usepackage{datetime}\renewcommand{\dateseparator}{-}
#+LATEX_HEADER_EXTRA:  \usepackage{xspace} % smart spaces
#+LATEX_HEADER_EXTRA:  \hypersetup{
#+LATEX_HEADER_EXTRA:    colorlinks=true,       % links are colored
#+LATEX_HEADER_EXTRA:    urlcolor=blue,    % color of external links
#+LATEX_HEADER_EXTRA:    linkcolor=blue,   % color of internal links
#+LATEX_HEADER_EXTRA:    citecolor=gray,   % color of links to bibliography
#+LATEX_HEADER_EXTRA:    draft=false, % link even in draft mode
#+LATEX_HEADER_EXTRA:    bookmarksopen=true, % ?
#+LATEX_HEADER_EXTRA:    pdfdisplaydoctitle=true}
#+LATEX_HEADER_EXTRA:  \renewcommand{\textfraction}{0.05}
#+LATEX_HEADER_EXTRA:  \renewcommand{\topfraction}{0.8}
#+LATEX_HEADER_EXTRA:  \renewcommand{\bottomfraction}{0.8}
#+LATEX_HEADER_EXTRA:  \renewcommand{\floatpagefraction}{0.75}

** Tweak References

# Make citations smaller 
# #+LATEX_HEADER_EXTRA: \let\realtextcite=\textcite
# #+LATEX_HEADER_EXTRA: \renewcommand{\textcite}[1]{{\scriptsize\textcolor{gray}{\realtextcite{#1}}}}
# #+LATEX_HEADER_EXTRA: \let\realautocite=\autocite
# #+LATEX_HEADER_EXTRA: \renewcommand{\autocite}[1]{{\scriptsize\textcolor{gray}{\realautocite{#1}}}}

#+LATEX_HEADER_EXTRA: \let\realtextcite=\textcite
#+LATEX_HEADER_EXTRA: \renewcommand{\textcite}[1]{{\textcolor{gray}{\realtextcite{#1}}}}
#+LATEX_HEADER_EXTRA: \let\realautocite=\autocite
#+LATEX_HEADER_EXTRA: \renewcommand{\autocite}[1]{{\textcolor{gray}{\realautocite{#1}}}}


** Background Block

# https://tex.stackexchange.com/questions/133955/beamer-how-to-place-images-behind-text-z-order
# % beamer: How to place images behind text (z-order) (http://tex.stackexchange.com/a/134311)
#+LATEX_HEADER_EXTRA: \makeatletter
#+LATEX_HEADER_EXTRA: \newbox\@backgroundblock
#+LATEX_HEADER_EXTRA: \newenvironment{backgroundblock}[2]{%
#+LATEX_HEADER_EXTRA:   \global\setbox\@backgroundblock=\vbox\bgroup%
#+LATEX_HEADER_EXTRA:     \unvbox\@backgroundblock%
#+LATEX_HEADER_EXTRA:     \vbox to0pt\bgroup\vskip#2\hbox to0pt\bgroup\hskip#1\relax%
#+LATEX_HEADER_EXTRA: }{\egroup\egroup\egroup}
#+LATEX_HEADER_EXTRA: \addtobeamertemplate{background}{\box\@backgroundblock}{}
#+LATEX_HEADER_EXTRA: \makeatother

# \begin{backgroundblock}{-3mm}{9mm}
# \includegraphics[height=\textheight]{./fig/Q.png}
# \end{backgroundblock}

** Code export

# (add-to-list 'org-latex-packages-alist '("minted"))
# (setq org-latex-listings 'minted)
# (setq org-latex-packages-alist nil)
# (setq org-latex-listings nil)

** COMMENT Embedded file
#+LATEX_HEADER_EXTRA: \usepackage{embedfile}
#+LATEX_HEADER_EXTRA: \embedfile{\jobname.org}

# \usepackage[main,include]{embedall}
# \IfFileExists{./\jobname.org}{\embedfile[desc=The original file]{\jobname.org}}{}

* Local Variables                                       :noexport:

# Local Variables:
# eval: (org-babel-lob-ingest "./lob.org")
# End:
